{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries and create spark session\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col,upper,udf,element_at,explode,regexp_replace,size\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StringType, DateType\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "import os\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"FHIR Analytics with Python\") \\\n",
    "    .config(\"spark.sql.extensions\", \"com.datastax.spark.connector.CassandraSparkExtensions\") \\\n",
    "    .getOrCreate()\n",
    "keyspace = \"myCatalog.hfs_data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a reference to our Cassandra catalog\n",
    "spark.conf.set(\"spark.sql.catalog.myCatalog\", \"com.datastax.spark.connector.datasource.CassandraCatalog\")\n",
    "\n",
    "# Increase memory for better performance\n",
    "spark.conf.set(\"spark.cassandra.input.split.sizeInMB\", \"67108864\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define UDFs to pull some data out of our structs\n",
    "def getMaritalStatus(ms):\n",
    "    if (ms == None):\n",
    "        return None\n",
    "    return ms.text_\n",
    "gms = udf(getMaritalStatus, StringType())\n",
    "def getBirthDate(bd):\n",
    "    return bd[0]\n",
    "gbd = udf(getBirthDate, DateType())\n",
    "\n",
    "# a reusable function to get a specific LOINC code and average all for by Patient ID\n",
    "def getAvgForLoinc(loinc_code, agg_column, df):\n",
    "    return df.filter(col(\"LoincCode\").like(loinc_code)) \\\n",
    "                         .withColumnRenamed(\"ValueQuantity\", agg_column) \\\n",
    "                         .select(col(\"Subject\"), col(agg_column)) \\\n",
    "                         .groupBy(\"Subject\").agg(F.round(F.avg(col(agg_column)), 3).alias(agg_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the tables we care about\n",
    "rawPatient = spark.read.table(keyspace + \".patient\")\n",
    "rawReference = spark.read.table(keyspace + \".reference\")\n",
    "rawObservation = spark.read.table(keyspace + \".observation\")\n",
    "rawEncounter = spark.read.table(keyspace + \".encounter\")\n",
    "\n",
    "# An alternative way to read tables, left for reference\n",
    "#rawReference = spark.read.format(\"org.apache.spark.sql.cassandra\").options(**{\"table\": \"reference\",\"keyspace\": \"hfs_data\"}).load()\n",
    "#rawObservation = spark.read.format(\"org.apache.spark.sql.cassandra\").options(**{\"table\": \"observation\",\"keyspace\": \"hfs_data\"}).load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "patientDataFrame = rawPatient.select(col(\"id\").alias(\"PatientId\"), gms(col(\"maritalstatus\")).alias(\"Marital Status\"), col(\"birthdate\")[\"0\"].alias(\"birthdate\"), upper(col(\"gender\")).alias(\"Gender\")).withColumn(\"Age\", F.round(F.datediff(F.current_date(), F.to_date(col(\"birthdate\"))) / 365, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3735"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patientDataFrame.cache()\n",
    "patientDataFrame.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only Patient references and manipulate the column values so they are ready for joining with other tables\n",
    "\n",
    "referenceDataFrame = rawReference.where(rawReference.reference.like(\"Patient%\")).select(regexp_replace(rawReference.id, \"#hidden\", \"\").alias(\"id\"), regexp_replace(rawReference.reference, \"Patient/\", \"\").alias(\"reference\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "895166"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "referenceDataFrame.cache()\n",
    "referenceDataFrame.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename some observation columns AND join with reference table to resolve Patient ID references properly\n",
    "\n",
    "observationDataFrame = rawObservation.select(col(\"id\").alias(\"ObservationId\"), col(\"code\"), col(\"component\"), col(\"valuequantity\"), col(\"subject\").alias(\"PatientReferenceId\"))\n",
    "observationDataFrame = observationDataFrame.join(referenceDataFrame, referenceDataFrame.id == observationDataFrame.PatientReferenceId) \\\n",
    "                  .withColumn(\"id\", col(\"id\").cast(StringType())).withColumn(\"reference\", col(\"reference\").cast(StringType())) \\\n",
    "                  .withColumnRenamed('reference', \"PatientId\") \\\n",
    "                  .drop(col(\"id\")) \\\n",
    "                  .drop(col(\"PatientReferenceId\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and select LOINC information from observation dataframe\n",
    "\n",
    "observationDataFrame_loinc = observationDataFrame \\\n",
    "    .select(col(\"PatientId\").alias(\"Subject\"), \\\n",
    "            col(\"ObservationId\"), \\\n",
    "            col(\"code\").coding[0].code.alias(\"LoincCode\"), \\\n",
    "            col(\"valuequantity\").value.alias(\"ValueQuantity\"))\n",
    "\n",
    "loinc_code_list = [\"8480-6\", \"8462-4\",\"29463-7\",\"8302-2\",\"33914-3\",\"2571-8\",\"2085-9\",\"18262-6\",\"2093-3\",\"39156-5\",\"55284-4\", \"195967001\", \"233678006\"]\n",
    "\n",
    "\n",
    "observationDataFrame_loinc = observationDataFrame_loinc \\\n",
    "    .filter(col(\"LoincCode\").isin(loinc_code_list))\\\n",
    "    .na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Subject: string, ObservationId: string, LoincCode: string, ValueQuantity: decimal(38,18)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observationDataFrame_loinc.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only Body Weight observations from pre-filtered observation data frame\n",
    "\n",
    "body_weight_df = observationDataFrame_loinc \\\n",
    "    .filter(col(\"LoincCode\").like(\"%29463-7%\")) \\\n",
    "    .withColumnRenamed(\"ValueQuantity\", \"Body Weight\") \\\n",
    "    .select(col(\"Subject\"), col(\"Body Weight\")) \\\n",
    "    .na.drop() \\\n",
    "    .dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Systolic, Dystolic and total BP, then avg per patient\n",
    "\n",
    "blood_pressure_df = observationDataFrame.select(col(\"PatientId\").alias(\"Subject\"),\n",
    "                          \"ObservationId\",\n",
    "                          col(\"component\")[0].code.coding[0].code.alias(\"DBPCode\"), \\\n",
    "                          col(\"component\")[0].valuequantity.value.alias(\"Diastolic Blood Pressure\"), \\\n",
    "                          col(\"component\")[1].code.coding[0].code.alias(\"SBPCode\"), \\\n",
    "                          col(\"component\")[1].valuequantity.value.alias(\"Systolic Blood Pressure\")).na.drop()\n",
    "\n",
    "\n",
    "\n",
    "blood_pressure_df = blood_pressure_df.withColumn(\"Blood Pressure\", \\\n",
    "      F.round(col(\"Diastolic Blood Pressure\")+(col(\"Systolic Blood Pressure\") - col(\"Diastolic Blood Pressure\"))/3))\n",
    "\n",
    "blood_pressure_avg_df = blood_pressure_df.groupBy(col(\"Subject\")).agg(F.round(F.avg(\"Diastolic Blood Pressure\"), 3).alias(\"Diastolic BP\"), \\\n",
    "                                           F.round(F.avg(\"Systolic Blood Pressure\"), 3).alias(\"Systolic BP\"), \\\n",
    "                                           F.round(F.avg(\"Blood Pressure\"), 3).alias(\"BP\") \\\n",
    "                                          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all encounters that show as Asthma diagnoses\n",
    "\n",
    "encounterDataFrame = rawEncounter.filter(F.size(col(\"reasoncode\")) > 0).select(col(\"subject\"), col(\"reasoncode\")[0].coding[0][\"code\"].alias(\"Asthma\")) \\\n",
    "                                 .withColumn(\"Asthma\", F.when(col(\"Asthma\").isin([\"195967001\",\"233678006\"]), F.lit(1)).otherwise(F.lit(0)))\n",
    "\n",
    "encounterDataFrame = encounterDataFrame.join(referenceDataFrame, encounterDataFrame.subject == referenceDataFrame.id) \\\n",
    "                                               .drop(\"subject\", \"id\") \\\n",
    "                                               .withColumnRenamed(\"reference\", \"subject\")\n",
    "\n",
    "encounterDataFrame_asthma = encounterDataFrame.groupBy(\"subject\").agg(F.max(col(\"Asthma\")).alias(\"Asthma\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate avg body weight per patient and join with patient data frame\n",
    "\n",
    "patient_calc_df = body_weight_df.groupBy(\"Subject\").agg(F.round(F.avg(\"Body Weight\"), 3).alias(\"Body Weight\")) \\\n",
    "                                .join(patientDataFrame, body_weight_df.Subject == patientDataFrame.PatientId) \\\n",
    "                                .drop(\"Subject\")\n",
    "\n",
    "#print(\"BW \" + str(patient_calc_df.count()))\n",
    "\n",
    "# Add literal demo info to patients\n",
    "patient_calc_df = patient_calc_df.dropDuplicates() \\\n",
    "                                 .withColumn(\"Disease\", F.array(F.lit(\"0\"))) \\\n",
    "                                 .withColumn(\"PostalCode\", F.array(F.lit(\"0\")))\n",
    "\n",
    "# Join BP info by patient\n",
    "# COMMENTED OUT BECAUSE LASSO\n",
    "patient_calc_df = patient_calc_df.join(blood_pressure_avg_df, \\\n",
    "                                             blood_pressure_avg_df.Subject == patient_calc_df.PatientId, \"left\") \\\n",
    "                                       .drop(\"Subject\")\n",
    "\n",
    "#print(\"BP \" + str(patient_calc_df.count()))\n",
    "     \n",
    "\n",
    "# Join asthma info by patient\n",
    "patient_calc_df = patient_calc_df.join(encounterDataFrame_asthma, encounterDataFrame_asthma.subject == patient_calc_df.PatientId, \"left\") \\\n",
    "                   .dropDuplicates() \\\n",
    "                   .drop(col(\"subject\"))\n",
    "\n",
    "#print(\"Asthma \" + str(patient_calc_df.count()))\n",
    "\n",
    "# Calculate and join avg triglycerides by patient\n",
    "triglycerides_df = getAvgForLoinc(\"%2571-8%\", \"Triglycerides\", observationDataFrame_loinc)\n",
    "\n",
    "patient_calc_df = patient_calc_df.join(triglycerides_df, patient_calc_df.PatientId == triglycerides_df.Subject, \"left\") \\\n",
    "                                 .drop(col(\"Subject\"))\n",
    "\n",
    "#print(\"Triglycerides \" + str(patient_calc_df.count()))\n",
    "\n",
    "\n",
    "# Calculate and join average EGFR by patient\n",
    "egfrLoincCode = [\"88294-4\", \"33914-3\"]\n",
    "agg_column = \"Estimated Glomerular Filtration Rate\"\n",
    "\n",
    "egfr_df = observationDataFrame_loinc.select(col(\"Subject\"), col(\"LoincCode\"), col(\"ValueQuantity\")) \\\n",
    "                                 .filter(col(\"LoincCode\").isin(egfrLoincCode)) \\\n",
    "                                 .withColumn(agg_column, col(\"ValueQuantity\")) \\\n",
    "                                 .groupBy(\"Subject\").agg(F.round(F.avg(col(agg_column))).alias(agg_column))\n",
    "\n",
    "# COMMENTED OUT BECAUSE LASSO\n",
    "patient_calc_df = patient_calc_df.join(egfr_df, patient_calc_df.PatientId == egfr_df.Subject, \"left\") \\\n",
    "                                 .drop(col(\"Subject\"))\n",
    "\n",
    "#print(\"EGFR \" + str(patient_calc_df.count()))\n",
    "\n",
    "\n",
    "# COMMENTED OUT BECAUSE LASSO\n",
    "# Calculate and join avg LDL by patient\n",
    "ldl_df = getAvgForLoinc(\"%18262-6%\", \"Low Density Lipoprotein\", observationDataFrame_loinc)\n",
    "\n",
    "patient_calc_df = patient_calc_df.join(ldl_df, patient_calc_df.PatientId == ldl_df.Subject, \"left\") \\\n",
    "                   .dropDuplicates().drop(col(\"Subject\"))\n",
    "\n",
    "#print(\"LDL \" + str(patient_calc_df.count()))\n",
    "\n",
    "\n",
    "# Calculate and join average HDL by patient\n",
    "hdl_df = getAvgForLoinc(\"%2085-9%\", \"High Density Lipoprotein Cholesterol\", observationDataFrame_loinc)\n",
    "\n",
    "patient_calc_df = patient_calc_df.join(hdl_df, patient_calc_df.PatientId == hdl_df.Subject, \"left\") \\\n",
    "                   .drop(col(\"Subject\"))\n",
    "\n",
    "#print(\"HDL \" + str(patient_calc_df.count()))\n",
    "\n",
    "\n",
    "# Calculate and join average height by patient\n",
    "height_df = getAvgForLoinc(\"%8302-2%\", \"Body Height\", observationDataFrame_loinc)\n",
    "\n",
    "patient_calc_df = patient_calc_df.join(height_df, patient_calc_df.PatientId == height_df.Subject, \"left\") \\\n",
    "                   .drop(col(\"Subject\"))\n",
    "\n",
    "#print(\"Height \" + str(patient_calc_df.count()))\n",
    "\n",
    "\n",
    "#Calculate and join average BMI by patient\n",
    "bmi_df = getAvgForLoinc(\"%39156-5%\", \"BMI\", observationDataFrame_loinc)\n",
    "    \n",
    "patient_calc_df = patient_calc_df.join(bmi_df, patient_calc_df.PatientId == bmi_df.Subject, \"left\") \\\n",
    "                   .drop(col(\"Subject\"))\n",
    "\n",
    "#print(\"BMI \" + str(patient_calc_df.count()))\n",
    "\n",
    "\n",
    "#Calculate and join average cholesterol by patient\n",
    "cholesterol_df = getAvgForLoinc(\"%2093-3%\", \"Total Cholesterol\", observationDataFrame_loinc)\n",
    "\n",
    "patient_calc_df = patient_calc_df.join(cholesterol_df, patient_calc_df.PatientId == cholesterol_df.Subject, \"left\") \\\n",
    "                   .drop(col(\"Subject\"))\n",
    "\n",
    "#print(\"Cholesterol \" + str(patient_calc_df.count()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "asthma_dataset = patient_calc_df.drop(\"PatientId\", \"Disease\", \"PostalCode\", \"birthdate\", \"Diagnosed Date\", \"Marital Status\").na.drop()\n",
    "#asthma_dataset = spark.read.csv(\"/Users/Harrison/projects/helios/analytics-blog-article/AsthmaDataset.csv\", header = True, inferSchema = True).drop(\"PatientId\", \"Disease\", \"PostalCode\", \"birthdate\", \"Diagnosed Date\", \"Birth Date\").na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asthma_dataset.cache()\n",
    "asthma_dataset.filter(col(\"Asthma\") ==1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Body Weight: decimal(38,3), Gender: string, Age: double, Diastolic BP: decimal(38,3), Systolic BP: decimal(38,3), BP: decimal(38,3), Asthma: int, Triglycerides: decimal(38,3), Estimated Glomerular Filtration Rate: decimal(38,0), Low Density Lipoprotein: decimal(38,3), High Density Lipoprotein Cholesterol: decimal(38,3), Body Height: decimal(38,3), BMI: decimal(38,3), Total Cholesterol: decimal(38,3)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asthma_dataset.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+-----+------------+-----------+-------+------+-------------+------------------------------------+-----------------------+------------------------------------+-----------+------+-----------------+\n",
      "|Body Weight|Gender|  Age|Diastolic BP|Systolic BP|     BP|Asthma|Triglycerides|Estimated Glomerular Filtration Rate|Low Density Lipoprotein|High Density Lipoprotein Cholesterol|Body Height|   BMI|Total Cholesterol|\n",
      "+-----------+------+-----+------------+-----------+-------+------+-------------+------------------------------------+-----------------------+------------------------------------+-----------+------+-----------------+\n",
      "|     89.700|  MALE| 81.7|      78.833|    116.167| 91.333|     0|      132.788|                                 119|                 78.340|                              67.913|    175.900|28.990|          172.810|\n",
      "|     88.725|  MALE| 56.9|      81.750|    119.375| 94.250|     0|      147.112|                                  78|                102.081|                              65.570|    175.200|29.486|          199.023|\n",
      "|     91.367|  MALE| 45.4|      66.078|    103.094| 78.167|     0|      189.303|                                  74|                101.096|                              53.026|    176.100|29.668|          191.655|\n",
      "|     80.000|FEMALE| 59.1|      82.667|    121.111| 95.556|     0|      151.965|                                  77|                119.172|                              68.713|    170.600|27.490|          190.472|\n",
      "|    123.260|  MALE| 48.2|      78.500|    122.500| 93.167|     0|      172.068|                                  81|                 99.122|                              65.394|    184.200|36.328|          177.659|\n",
      "|     82.200|  MALE|101.5|      79.700|    122.400| 93.800|     0|      117.623|                                  15|                 73.555|                              71.028|    172.700|27.560|          168.108|\n",
      "|     84.200|  MALE| 58.1|      77.000|    123.909| 92.636|     0|      149.006|                                  76|                107.866|                              55.361|    171.600|28.590|          181.248|\n",
      "|     64.800|FEMALE| 54.3|      91.125|    133.375|105.250|     0|      125.845|                                 111|                 89.728|                              66.705|    152.600|27.830|          181.605|\n",
      "|     84.500|  MALE| 41.1|      82.833|    131.250| 99.000|     0|      163.393|                                 127|                121.269|                              54.531|    175.400|27.470|          208.479|\n",
      "|     89.600|  MALE| 60.5|      76.700|    121.900| 91.800|     0|      151.459|                                  81|                104.145|                              65.149|    177.400|28.112|          188.517|\n",
      "|    107.900|  MALE| 42.1|      77.500|    115.167| 90.167|     0|      142.973|                                  68|                104.573|                              59.379|    171.600|36.648|          203.170|\n",
      "|     84.700|FEMALE| 42.4|      66.920|     98.988| 77.636|     0|      177.820|                                  76|                119.448|                              56.174|    171.300|28.957|          202.783|\n",
      "|     88.200|  MALE| 56.7|      79.909|    124.091| 94.546|     0|      136.210|                                 124|                 84.030|                              70.625|    174.500|29.156|          181.898|\n",
      "|    109.200|  MALE| 52.4|      77.286|    120.429| 91.571|     0|      111.930|                                 153|                 87.060|                              69.953|    193.300|29.230|          179.403|\n",
      "|     56.300|FEMALE| 43.9|      77.800|    115.000| 90.200|     0|      176.768|                                 131|                133.705|                              50.813|    160.100|21.960|          219.868|\n",
      "|     77.711|FEMALE| 57.6|      78.300|    119.200| 91.800|     0|      247.258|                                  84|                113.959|                              50.388|    163.000|29.280|          213.799|\n",
      "|     94.200|  MALE| 52.7|      79.750|    118.375| 92.750|     0|      133.543|                                  66|                107.687|                              57.492|    178.300|29.630|          214.797|\n",
      "|     91.800|  MALE| 84.7|      80.778|    116.333| 92.667|     0|      153.545|                                  46|                 88.838|                              59.866|    181.900|27.740|          209.573|\n",
      "|     89.600|  MALE| 36.8|     101.900|    155.300|119.700|     0|      181.443|                                 126|                128.883|                              47.561|    175.800|28.873|          212.734|\n",
      "|     88.775|  MALE| 48.3|      76.800|    116.200| 89.800|     0|      152.768|                                  78|                 98.328|                              54.338|    175.200|29.182|          209.320|\n",
      "+-----------+------+-----+------------+-----------+-------+------+-------------+------------------------------------+-----------------------+------------------------------------+-----------+------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "asthma_dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asthma_dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+----+------------+-----------+-------+------+-------------+------------------------------------+-----------------------+------------------------------------+-----------+------+-----------------+\n",
      "|Body Weight|Gender| Age|Diastolic BP|Systolic BP|     BP|Asthma|Triglycerides|Estimated Glomerular Filtration Rate|Low Density Lipoprotein|High Density Lipoprotein Cholesterol|Body Height|   BMI|Total Cholesterol|\n",
      "+-----------+------+----+------------+-----------+-------+------+-------------+------------------------------------+-----------------------+------------------------------------+-----------+------+-----------------+\n",
      "|     77.820|FEMALE|38.3|     100.600|    147.300|116.200|     1|      184.088|                                 129|                136.573|                              46.143|    152.700|33.703|          219.530|\n",
      "+-----------+------+----+------------+-----------+-------+------+-------------+------------------------------------+-----------------------+------------------------------------+-----------+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "asthma_dataset.filter(col(\"Asthma\") == 1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 77 rows in the training set and 17 in the test set\n"
     ]
    }
   ],
   "source": [
    "trainDF, testDF = asthma_dataset.randomSplit([.8, .2], seed = 42)\n",
    "print(f\"\"\"There are {trainDF.count()} rows in the training set and {testDF.count()} in the test set\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_asthma = trainDF.groupBy(\"Asthma\").count().select(\"count\").filter(col(\"Asthma\") == 1).first()[0]\n",
    "# ratio = num_asthma/trainDF.count()\n",
    "\n",
    "# trainDF = trainDF.withColumn(\"weights\", F.when(trainDF.Asthma == 1, 1-ratio).otherwise(ratio))\n",
    "# trainDF.select(\"Asthma\", \"weights\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalCols = [field for (field, dataType) in trainDF.dtypes if dataType == \"string\"]\n",
    "indexOutputCols = [x + \"Index\" for x in categoricalCols]\n",
    "oheOutputCols = [x + \"OHE\" for x in categoricalCols]\n",
    "\n",
    "stringIndexer = StringIndexer(inputCols = categoricalCols, outputCols = indexOutputCols, handleInvalid = \"skip\")\n",
    "oheEncoder = OneHotEncoder(inputCols = indexOutputCols, outputCols = oheOutputCols)\n",
    "\n",
    "numericCols = [field for (field, dataType) in trainDF.dtypes\n",
    "                if dataType != \"string\" and field != \"Asthma\"]\n",
    "\n",
    "assemblerInputs = oheOutputCols + numericCols\n",
    "\n",
    "vecAssembler = VectorAssembler(inputCols = assemblerInputs, outputCol = \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+-----+------------+-----------+-------+------+-------------+------------------------------------+-----------------------+------------------------------------+-----------+------+-----------------+\n",
      "|Body Weight|Gender|Age  |Diastolic BP|Systolic BP|BP     |Asthma|Triglycerides|Estimated Glomerular Filtration Rate|Low Density Lipoprotein|High Density Lipoprotein Cholesterol|Body Height|BMI   |Total Cholesterol|\n",
      "+-----------+------+-----+------------+-----------+-------+------+-------------+------------------------------------+-----------------------+------------------------------------+-----------+------+-----------------+\n",
      "|89.700     |MALE  |81.7 |78.833      |116.167    |91.333 |0     |132.788      |119                                 |78.340                 |67.913                              |175.900    |28.990|172.810          |\n",
      "|88.725     |MALE  |56.9 |81.750      |119.375    |94.250 |0     |147.112      |78                                  |102.081                |65.570                              |175.200    |29.486|199.023          |\n",
      "|80.000     |FEMALE|59.1 |82.667      |121.111    |95.556 |0     |151.965      |77                                  |119.172                |68.713                              |170.600    |27.490|190.472          |\n",
      "|91.367     |MALE  |45.4 |66.078      |103.094    |78.167 |0     |189.303      |74                                  |101.096                |53.026                              |176.100    |29.668|191.655          |\n",
      "|82.200     |MALE  |101.5|79.700      |122.400    |93.800 |0     |117.623      |15                                  |73.555                 |71.028                              |172.700    |27.560|168.108          |\n",
      "|123.260    |MALE  |48.2 |78.500      |122.500    |93.167 |0     |172.068      |81                                  |99.122                 |65.394                              |184.200    |36.328|177.659          |\n",
      "|84.200     |MALE  |58.1 |77.000      |123.909    |92.636 |0     |149.006      |76                                  |107.866                |55.361                              |171.600    |28.590|181.248          |\n",
      "|84.500     |MALE  |41.1 |82.833      |131.250    |99.000 |0     |163.393      |127                                 |121.269                |54.531                              |175.400    |27.470|208.479          |\n",
      "|89.600     |MALE  |60.5 |76.700      |121.900    |91.800 |0     |151.459      |81                                  |104.145                |65.149                              |177.400    |28.112|188.517          |\n",
      "|84.700     |FEMALE|42.4 |66.920      |98.988     |77.636 |0     |177.820      |76                                  |119.448                |56.174                              |171.300    |28.957|202.783          |\n",
      "|56.300     |FEMALE|43.9 |77.800      |115.000    |90.200 |0     |176.768      |131                                 |133.705                |50.813                              |160.100    |21.960|219.868          |\n",
      "|109.200    |MALE  |52.4 |77.286      |120.429    |91.571 |0     |111.930      |153                                 |87.060                 |69.953                              |193.300    |29.230|179.403          |\n",
      "|77.711     |FEMALE|57.6 |78.300      |119.200    |91.800 |0     |247.258      |84                                  |113.959                |50.388                              |163.000    |29.280|213.799          |\n",
      "|94.200     |MALE  |52.7 |79.750      |118.375    |92.750 |0     |133.543      |66                                  |107.687                |57.492                              |178.300    |29.630|214.797          |\n",
      "|88.775     |MALE  |48.3 |76.800      |116.200    |89.800 |0     |152.768      |78                                  |98.328                 |54.338                              |175.200    |29.182|209.320          |\n",
      "|89.600     |MALE  |36.8 |101.900     |155.300    |119.700|0     |181.443      |126                                 |128.883                |47.561                              |175.800    |28.873|212.734          |\n",
      "|88.200     |MALE  |43.1 |81.250      |108.000    |90.250 |0     |171.803      |82                                  |98.725                 |65.735                              |178.500    |27.680|208.623          |\n",
      "|78.100     |MALE  |65.6 |78.600      |124.600    |94.000 |0     |116.980      |9                                   |84.263                 |75.693                              |167.200    |27.940|183.347          |\n",
      "|91.775     |MALE  |51.6 |79.000      |124.429    |94.000 |0     |170.603      |82                                  |103.050                |51.511                              |180.200    |29.245|176.879          |\n",
      "|62.230     |MALE  |27.7 |107.333     |157.083    |123.917|0     |160.005      |117                                 |144.375                |48.605                              |171.518    |21.234|224.980          |\n",
      "+-----------+------+-----+------------+-----------+-------+------+-------------+------------------------------------+-----------------------+------------------------------------+-----------+------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------+------+----------+------+\n",
      "|features|Asthma|prediction|Gender|\n",
      "+--------+------+----------+------+\n",
      "+--------+------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a model one time, see a baseline using Generalized Linear Regression\n",
    "\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "\n",
    "glm = GeneralizedLinearRegression(family = \"binomial\", labelCol = \"Asthma\")\n",
    "glm_pipeline = Pipeline(stages = [stringIndexer, oheEncoder, vecAssembler, glm])\n",
    "\n",
    "trainDF.show(truncate = False)\n",
    "glm_model = glm_pipeline.fit(trainDF)\n",
    "predDF = glm_model.transform(testDF)\n",
    "\n",
    "#summary = glm_model.stages[-1].summary\n",
    "# print(\"Coefficient Standard Errors: \" + str(summary.coefficientStandardErrors))\n",
    "# print(\"T Values: \" + str(summary.tValues))\n",
    "# print(\"P Values: \" + str(summary.pValues))\n",
    "# print(\"Dispersion: \" + str(summary.dispersion))\n",
    "# print(\"Null Deviance: \" + str(summary.nullDeviance))\n",
    "# print(\"Residual Degree Of Freedom Null: \" + str(summary.residualDegreeOfFreedomNull))\n",
    "# print(\"Deviance: \" + str(summary.deviance))\n",
    "# print(\"Residual Degree Of Freedom: \" + str(summary.residualDegreeOfFreedom))\n",
    "# print(\"AIC: \" + str(summary.aic))\n",
    "# print(\"Deviance Residuals: \")\n",
    "# summary.residuals().show()\n",
    "# print(summary)\n",
    "predDF.select(\"features\", \"Asthma\", \"prediction\", \"Gender\").filter(col(\"Asthma\") == 1).show()\n",
    "\n",
    "## Check if we have GenderOHE_FEMALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|Asthma|          prediction|\n",
      "+------+--------------------+\n",
      "|     0|6.485247738964128...|\n",
      "|     0|3.613388537075863...|\n",
      "|     0|             1.0E-16|\n",
      "|     0|             1.0E-16|\n",
      "|     0|             1.0E-16|\n",
      "|     0|             1.0E-16|\n",
      "|     0|3.154426051761708...|\n",
      "|     0|3.801658789252083...|\n",
      "|     0|             1.0E-16|\n",
      "|     0|             1.0E-16|\n",
      "|     0|             1.0E-16|\n",
      "|     0|             1.0E-16|\n",
      "|     0|             1.0E-16|\n",
      "|     0|             1.0E-16|\n",
      "|     0|             1.0E-16|\n",
      "|     0|             1.0E-16|\n",
      "|     0|             1.0E-16|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use CrossValidator to select the best model from 2 possible regParams\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(glm.regParam, [0.1, 0.01]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=glm_pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=RegressionEvaluator(labelCol = \"Asthma\"),\n",
    "                          numFolds=2\n",
    "                         )  # use 3+ folds in practice\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "cvModel = crossval.fit(trainDF)\n",
    "prediction = cvModel.transform(testDF)\n",
    "selected = prediction.select(\"Asthma\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:\n",
      "             Feature Estimate    Std Error T Value P Value\n",
      "         (Intercept)   5.4238 3326550.6240  0.0000  1.0000\n",
      "      GenderOHE_MALE  -0.0645   62155.5389  0.0000  1.0000\n",
      "         Body Weight   0.9099   19774.1400  0.0000  1.0000\n",
      "                 Age   0.0517    9897.9016  0.0000  1.0000\n",
      "        Diastolic BP   0.5884   44531.4956  0.0000  1.0000\n",
      "         Systolic BP  -0.4232   28224.0135  0.0000  1.0000\n",
      "                  BP   0.2588   50941.6582  0.0000  1.0000\n",
      "       Triglycerides   0.0121    6831.6685  0.0000  1.0000\n",
      "Estimated Glomeru...   0.2562    3715.7622  0.0001  0.9999\n",
      "Low Density Lipop...   0.0749   22698.8167  0.0000  1.0000\n",
      "High Density Lipo...  -0.0294   33295.8135  0.0000  1.0000\n",
      "         Body Height  -1.8624   20665.8911 -0.0001  0.9999\n",
      "                 BMI   1.1022   53069.4640  0.0000  1.0000\n",
      "   Total Cholesterol   0.5459   23485.7555  0.0000  1.0000\n",
      "\n",
      "(Dispersion parameter for binomial family taken to be 1.0000)\n",
      "   Null deviance: 10.6746 on 63 degrees of freedom\n",
      "Residual deviance: 0.0000 on 63 degrees of freedom\n",
      "AIC: 28.0000\n"
     ]
    }
   ],
   "source": [
    "# Print the summary (need help interpreting this)\n",
    "\n",
    "trainingSummary = cvModel.bestModel.stages[-1].summary\n",
    "\n",
    "print(trainingSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-2.5318347181054275,-0.04459336258051747,-0.031900724741654306,0.11905140147548993,0.05410605229101334,0.09241761273526654,0.015584702677107482,0.01629516802287645,0.02759625317541442,-0.14901724113786272,-0.22263782774010563,0.3958524860030187,0.00764123815383942]\n",
      "Intercept: -4.378136616114738\n",
      "<pyspark.ml.classification.BinaryLogisticRegressionTrainingSummary object at 0x122cf3af0>\n",
      "['Body Weight', 'Gender', 'Age', 'Diastolic BP', 'Systolic BP', 'BP', 'Asthma', 'Triglycerides', 'Estimated Glomerular Filtration Rate', 'Low Density Lipoprotein', 'High Density Lipoprotein Cholesterol', 'Body Height', 'BMI', 'Total Cholesterol', 'GenderIndex', 'GenderOHE', 'features', 'rawPrediction', 'probability', 'prediction']\n",
      "+--------+------+----------+\n",
      "|features|Asthma|prediction|\n",
      "+--------+------+----------+\n",
      "+--------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try a \"default\" Logistic Regression\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(labelCol = \"Asthma\", featuresCol = \"features\", maxIter=10)\n",
    "pipeline = Pipeline(stages = [stringIndexer, oheEncoder, vecAssembler, lr])\n",
    "\n",
    "# Fit the model\n",
    "lrModel = pipeline.fit(trainDF)\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(lrModel.stages[-1].coefficients))\n",
    "print(\"Intercept: \" + str(lrModel.stages[-1].intercept))\n",
    "\n",
    "print(lrModel.stages[-1].summary)\n",
    "\n",
    "\n",
    "predDF = lrModel.transform(testDF)\n",
    "\n",
    "print(predDF.schema.names)\n",
    "\n",
    "predDF.select(\"features\", \"Asthma\", \"prediction\").filter(\"Asthma > 0\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.na.drop().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objectiveHistory:\n",
      "0.06931537170094178\n",
      "0.06814456134613474\n",
      "0.059685310050892657\n",
      "0.028902506543761274\n",
      "0.02041662641407601\n",
      "0.012745281897140283\n",
      "0.007304360091786571\n",
      "0.0035943083060730845\n",
      "0.0018256087139155073\n",
      "0.0009152221830390941\n",
      "0.0004630651710574936\n",
      "+--------------------+---+\n",
      "|                 FPR|TPR|\n",
      "+--------------------+---+\n",
      "|                 0.0|0.0|\n",
      "|                 0.0|1.0|\n",
      "|0.013157894736842105|1.0|\n",
      "| 0.02631578947368421|1.0|\n",
      "|0.039473684210526314|1.0|\n",
      "| 0.05263157894736842|1.0|\n",
      "| 0.06578947368421052|1.0|\n",
      "| 0.07894736842105263|1.0|\n",
      "| 0.09210526315789473|1.0|\n",
      "| 0.10526315789473684|1.0|\n",
      "| 0.11842105263157894|1.0|\n",
      "| 0.13157894736842105|1.0|\n",
      "| 0.14473684210526316|1.0|\n",
      "| 0.15789473684210525|1.0|\n",
      "| 0.17105263157894737|1.0|\n",
      "| 0.18421052631578946|1.0|\n",
      "| 0.19736842105263158|1.0|\n",
      "| 0.21052631578947367|1.0|\n",
      "|  0.2236842105263158|1.0|\n",
      "| 0.23684210526315788|1.0|\n",
      "+--------------------+---+\n",
      "only showing top 20 rows\n",
      "\n",
      "areaUnderROC: 1.0\n",
      "+--------------+\n",
      "|max(F-Measure)|\n",
      "+--------------+\n",
      "|           1.0|\n",
      "+--------------+\n",
      "\n",
      "0.9890246156428234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression_477a49cb3856"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### DON'T REALLY KNOW WHAT THIS DOES - it seems like 'lr.setThreshold' is supposed to improve the prediction ability\n",
    "\n",
    "# Extract the summary from the returned LogisticRegressionModel instance trained\n",
    "# in the earlier example\n",
    "trainingSummary = lrModel.stages[-1].summary\n",
    "\n",
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "# Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.\n",
    "trainingSummary.roc.show()\n",
    "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))\n",
    "\n",
    "# Set the model threshold to maximize F-Measure\n",
    "fMeasure = trainingSummary.fMeasureByThreshold\n",
    "maxFMeasure = fMeasure.groupBy().max('F-Measure').select('max(F-Measure)').head()\n",
    "bestThreshold = fMeasure.where(fMeasure['F-Measure'] == maxFMeasure['max(F-Measure)']) \\\n",
    "    .select('threshold').head()['threshold']\n",
    "fMeasure.groupBy().max('F-Measure').select('max(F-Measure)').show()\n",
    "print(bestThreshold)\n",
    "lr.setThreshold(bestThreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Body Weight', 'Gender', 'Age', 'Diastolic BP', 'Systolic BP', 'BP', 'Asthma', 'Triglycerides', 'Estimated Glomerular Filtration Rate', 'Low Density Lipoprotein', 'High Density Lipoprotein Cholesterol', 'Body Height', 'BMI', 'Total Cholesterol', 'GenderIndex', 'GenderOHE', 'features', 'rawPrediction', 'probability', 'prediction']\n",
      "+------+----------+-----------+\n",
      "|Asthma|prediction|probability|\n",
      "+------+----------+-----------+\n",
      "+------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predDF = lrModel.transform(testDF)\n",
    "\n",
    "print(predDF.schema.names)\n",
    "\n",
    "predDF.select(\"Asthma\", \"prediction\", \"probability\").filter(\"Asthma == 1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|Asthma|prediction|\n",
      "+------+----------+\n",
      "+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(labelCol = \"Asthma\"),\n",
    "                          numFolds=2\n",
    "                         )  # use 3+ folds in practice\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "cvModel = crossval.fit(trainDF)\n",
    "prediction = cvModel.transform(testDF)\n",
    "selected = prediction.select(\"Asthma\", \"prediction\").where(col(\"Asthma\") == 1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-84dd6000ab1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mroc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlrModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FPR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mroc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TPR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'False Positive Rate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'True Positive Rate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ROC Curve'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "roc = lrModel.stages[-1].summary.roc.toPandas()\n",
    "plt.plot(roc['FPR'],roc['TPR'])\n",
    "plt.ylabel('False Positive Rate')\n",
    "plt.xlabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "print('Training set areaUnderROC for untuned model: ' + str(lrModel.stages[-1].summary.areaUnderROC))\n",
    "\n",
    "roc = cvModel.bestModel.stages[-1].summary.roc.toPandas()\n",
    "plt.plot(roc['FPR'],roc['TPR'])\n",
    "plt.ylabel('False Positive Rate')\n",
    "plt.xlabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "print('Training set areaUnderROC for BEST model: ' + str(cvModel.bestModel.stages[-1].summary.areaUnderROC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(labelCol = \"Asthma\", featuresCol = \"features\", maxIter=10, elasticNetParam = 1)\n",
    "# lr.setThreshold(bestThreshold)\n",
    "pipeline = Pipeline(stages = [stringIndexer, oheEncoder, vecAssembler, lr])\n",
    "\n",
    "# Fit the model\n",
    "lrModel = pipeline.fit(trainDF)\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(lrModel.stages[-1].coefficients))\n",
    "print(\"Intercept: \" + str(lrModel.stages[-1].intercept))\n",
    "\n",
    "print(str(lrModel.stages[-1].summary.accuracy))\n",
    "\n",
    "predDF = lrModel.transform(testDF)\n",
    "\n",
    "predDF.select(\"features\", \"Asthma\", \"prediction\").filter((col(\"Asthma\") ==1)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DON'T REALLY KNOW WHAT THIS DOES - it seems like 'lr.setThreshold' is supposed to improve the prediction ability\n",
    "\n",
    "# Extract the summary from the returned LogisticRegressionModel instance trained\n",
    "# in the earlier example\n",
    "trainingSummary = cvModel.bestModel.stages[-1].summary\n",
    "\n",
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "# Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.\n",
    "trainingSummary.roc.show()\n",
    "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))\n",
    "\n",
    "# Set the model threshold to maximize F-Measure\n",
    "fMeasure = trainingSummary.fMeasureByThreshold\n",
    "maxFMeasure = fMeasure.groupBy().max('F-Measure').select('max(F-Measure)').head()\n",
    "print(maxFMeasure)\n",
    "bestThreshold = fMeasure.where(fMeasure['F-Measure'] == maxFMeasure['max(F-Measure)']) \\\n",
    "    .select('threshold').head()['threshold']\n",
    "print(bestThreshold)\n",
    "#lr.setThreshold(bestThreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01, 0.05, .3]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(labelCol = \"Asthma\"),\n",
    "                          numFolds=2\n",
    "                         )  # use 3+ folds in practice\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "cvModel = crossval.fit(trainDF)\n",
    "prediction = cvModel.transform(testDF)\n",
    "selected = prediction.select(\"Asthma\", \"prediction\").where((col(\"Asthma\") == 1)).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = lrModel.stages[-1].summary.roc.toPandas()\n",
    "plt.plot(roc['FPR'],roc['TPR'])\n",
    "plt.ylabel('False Positive Rate')\n",
    "plt.xlabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "print('Training set areaUnderROC for untuned model: ' + str(lrModel.stages[-1].summary.areaUnderROC))\n",
    "\n",
    "roc = cvModel.bestModel.stages[-1].summary.roc.toPandas()\n",
    "plt.plot(roc['FPR'],roc['TPR'])\n",
    "plt.ylabel('False Positive Rate')\n",
    "plt.xlabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "print('Training set areaUnderROC for BEST model: ' + str(cvModel.bestModel.stages[-1].summary.areaUnderROC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(lrModel.stages[-1].summary.truepositive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
